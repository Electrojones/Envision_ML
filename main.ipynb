{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9DFCxbmJrmIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgwD3bZ-rb66"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade keras-cv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner -q"
      ],
      "metadata": {
        "id": "WPi_m5vvQrdI",
        "outputId": "c68a36a4-25ad-4506-a764-161d93d730c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/129.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "from tensorflow import data as tf_data\n",
        "import matplotlib.pyplot as plt\n",
        "import keras_cv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "CP8lk1SZsaJK"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading training data\n",
        "image_size = (224, 224)\n",
        "batch_size = 128\n",
        "\n",
        "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
        "    \"drive/MyDrive/envis_train_data\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"both\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqOySa5FsgaM",
        "outputId": "27c9ba60-0d98-4c3e-95be-0a7e05a379b5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2065 files belonging to 4 classes.\n",
            "Using 1652 files for training.\n",
            "Using 413 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining data augumentation\n",
        "data_augmentation_layers = [\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "]\n",
        "\n",
        "\n",
        "def data_augmentation(images):\n",
        "    for layer in data_augmentation_layers:\n",
        "        images = layer(images)\n",
        "    return images\n",
        "\n",
        "# Applying the augumentation\n",
        "train_ds = train_ds.map(\n",
        "    lambda img, label: (data_augmentation(img), label),\n",
        "    num_parallel_calls=tf_data.AUTOTUNE,\n",
        ")\n",
        "# Prefetching the data\n",
        "train_ds = train_ds.prefetch(tf_data.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(tf_data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "QhaT1G-dtrqH"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained mobilenet\n",
        "base_model = keras_cv.models.MobileNetV3Backbone.from_preset(\n",
        "    \"mobilenet_v3_large_imagenet\",\n",
        ")\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "PNnKli79u8oQ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some model architectures:\n",
        "\n",
        "# Transfer learning with mobilenet:\n",
        "# first adding the mobile net backbone\n",
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "#x = layers.Flatten()(x)\n",
        "\n",
        "# Some fully connected layers\n",
        "x = keras.layers.Dense(100, activation='relu')(x)\n",
        "x = keras.layers.Dense(100, activation='relu')(x)\n",
        "x = keras.layers.Dense(50, activation='relu')(x)\n",
        "x = keras.layers.Dense(50, activation='relu')(x)\n",
        "x = keras.layers.Dense(50, activation='relu')(x)\n",
        "x = keras.layers.Dense(20, activation='relu')(x)\n",
        "outputs = keras.layers.Dense(4, activation='softmax')(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Just a pure CNN trained from scratch\n",
        "'''model = Sequential()\n",
        "model.add(Conv2D(200, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "model.add(Conv2D(100, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "model.add(Conv2D(50, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))'''\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "2EUeE29hwI_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])"
      ],
      "metadata": {
        "id": "EaecOXGpxrxq"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, epochs=20, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "EYRQi6hlx1XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tuning:\n",
        "base_model.trainable = True\n",
        "model.summary(show_trainable=True)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "\n",
        "model.fit(train_ds, epochs=4, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "XGA1jH79Kcj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"envis_model_mobilenetv3_backbone.keras\")"
      ],
      "metadata": {
        "id": "PXId3yQPM30q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}